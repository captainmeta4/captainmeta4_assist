import praw
import urllib.parse as urlparse
import os

#Initiate reddit
r=praw.Reddit(user_agent='reddit repost detector running under /u/captainmeta4')

#Set globals
username='PoliticsModeratorBot'

subredditname='mod'

requires_params=[
    'hosted.ap.org',
    'c-span.org',
    'defense.gov',
    'fec.gov',
    'governmentisgood.com',
    'house.gov',
    'liveleak.com',
    'nationalpost.com',
    'news-republic.com',
    'senate.gov',
    'surveyusa.com',
    'quinnipiac.edu',
    'unionleader.com',
    'youtu.be',
    'youtube.com'
    ]

#Feature not yet deployed
#zero_false_positive=[
#    'bostonglobe.com',
#    'cnn.com',
#    'latimes.com',
#    'nytimes.com'
#    'washingtonpost.com',
#    'vox.com'
#    ]

class bot():

    def login(self):
        r.login(username,os.environ.get('password'))

    def process_submissions(self):

        #Collect unending submission stream
        for submission in praw.helpers.submission_stream(r, subredditname, limit=100, verbosity=0):
            print('checking '+submission.title)
            
            #ignore self-posts
            if submission.is_self:
                continue
            
            #ignore posts that have been mod-approved
            if submission.approved_by is not None:
                continue

            #break down url
            ParsedURL = urlparse.urlparse(submission.url)

            #strip params and query unless it's a site known to need them
            if any(entry in submission.domain for entry in requires_params):
                params=ParsedURL[3]
                query=ParsedURL[4]
            else:
                params=''
                query=''
                
            #strip mobile. subdomain away from netloc
            netloc=ParsedURL[1]
            netloc=netloc.replace('mobile.','',1)
                
            #strip fragments and assemble url to search for,
            NewParsedURL=urlparse.ParseResult(
                scheme=ParsedURL[0],
                netloc=netloc,
                path=ParsedURL[2],
                params=params,
                query=query,
                fragment=''
                )
            url=urlparse.urlunparse(NewParsedURL)
            
            #strip away schema
            url=url.replace('http://','',1)
            url=url.replace('https://','',1)
            #print(url)
            
            #create search string
            search = "url:"+url
            
            #count prior duplicates
            dupe_list = []

            #Search subreddit for other posts that match            
            for searchresult in r.search(search,subreddit=submission.subreddit, sort='New'):

                #Ignore the original post
                if searchresult.id == submission.id:
                    continue

                #Ignore newer posts - only flag if there's an older post
                if searchresult.created_utc > submission.created_utc:
                    continue

                #Ignore false positives generated by reddit search being silly
                if url not in searchresult.url:
                    continue

                #At this point we know it's a repost (odd url constructions notwithstanding)
                #Now we have to see if it complies with repost policy
                
                #count the duplicate
                dupe_list.append(searchresult.id)
                
                #check original post age and remove if needed
                age = submission.created_utc - searchresult.created_utc
                if age < (60 * 60 * 24 * 3):  #3 days, in seconds
                    self.three_days_remove(submission, searchresult.id)
                    break
                
                #check original post score and remove if needed
                if searchresult.score >=20:
                    self.score_remove(submission, searchresult.id)
                    break
                
                #check repost count and remove if needed
                if len(dupe_list) > 3:
                    self.three_posts_remove(submission, dupe_list)
                    break
    
    def three_days_remove(self, submission, id):
        submission.remove()
        submission.set_flair(flair_text="Already Submitted")
        msg = ("Hi `%(author)s`. Thank you for participating in /r/Politics. However, your submission has been removed for the following reason:"
                "\n\n"
                "* Already Submitted: This article has been submitted to /r/politics within the last three days:"
                "\n\n http://redd.it/%(id)s"
                "\n\n"
                "I'm a bot and sometimes I make mistakes. If you have any questions about this removal, please feel free to [message the moderators.]"
                "(https://www.reddit.com/message/compose?to=/r/politics&subject=Question regarding the removal of this submission by /u/%(author)s&message=I have a question regarding the removal of this [submission.](%(url)s\))"
                )
        submission.add_comment(msg % {"author":str(submission.author), "id":id, "url":submission.permalink}).distinguish()
        
    def score_remove(self, submission, id):
        submission.remove()
        submission.set_flair(flair_text="Already Submitted")
        msg = ("Hi `%(author)s`. Thank you for participating in /r/Politics. However, your submission has been removed for the following reason:"
                "\n\n"
                "* Already Submitted: An earlier duplicate of this post received some upvotes:"
                "\n\n http://redd.it/%(id)s"
                "\n\n"
                "I'm a bot and sometimes I make mistakes. If you have any questions about this removal, please feel free to [message the moderators.]"
                "(https://www.reddit.com/message/compose?to=/r/politics&subject=Question regarding the removal of this submission by /u/%(author)s&message=I have a question regarding the removal of this [submission.](%(url)s\))"
                )
        submission.add_comment(msg % {"author":str(submission.author), "id":id, "url":submission.permalink}).distinguish()
    
    def three_posts_remove(self, submission, dupe_list):
        submission.remove()
        submission.set_flair(flair_text="Already Submitted")
        msg = ("Hi `%(author)s`. Thank you for participating in /r/Politics. However, your submission has been removed for the following reason:"
                "\n\n"
                "* Already Submitted: This article has already been submitted to /r/politics three times:"
                "\n\n http://redd.it/%(id1)s"
                "\n\n http://redd.it/%(id2)s"
                "\n\n http://redd.it/%(id3)s"
                "\n\n"
                "I'm a bot and sometimes I make mistakes. If you have any questions about this removal, please feel free to [message the moderators.]"
                "(https://www.reddit.com/message/compose?to=/r/politics&subject=Question regarding the removal of this submission by /u/%(author)s&message=I have a question regarding the removal of this [submission.](%(url)s\))"
                )
        params = {"author":str(submission.author), "url":submission.permalink}
        params['id1']=dupe_list[0]
        params['id2']=dupe_list[1]
        params['id3']=dupe_list[2]
        submission.add_comment(msg % params).distinguish()

        
    def run(self):
        self.login()
        self.process_submissions()

if __name__=='__main__':
    modbot=bot()
    modbot.run()
